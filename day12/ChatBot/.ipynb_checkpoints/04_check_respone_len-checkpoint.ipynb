{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6aeea9d9-e1f4-45fb-82ee-7c13d6289958",
   "metadata": {},
   "source": [
    "### 멀티턴 방식을 선택하는 기준"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ecdbf2-731c-41d8-87d1-384b94a78d7b",
   "metadata": {},
   "source": [
    "제미나이와 멀티턴으로 메시지를 주고받을 때 두 가지 형태의 API 사용법이 존재한다는 사실을 확인했습니다. 만일, 사용자와 모델 간의 대화 사이에 프로그램의 개입이 필요 없다면, 멀티턴 방식 중 첫 번째인 ChatSession 객체만 활용해도 충분합니다. 그러나, 어떤 이유로든 메시지 입력 → 전송 → 모델 응답 과정에서 사용자 프로그램의 개입이 필요하다면, 멀티턴 방식 중 두 번째 것을 사용하는 것이 좋습니다. 다음은 모델의 응답 메시지 길이를 40글자 이내로 맞춰야 하는 상황을 가정했습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdda2c55-6765-4436-aba5-b82ee41eafca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Dev\\Python\\Python312\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[사용자]: 인공지능에 대해 40자 이내의 문장으로 설명하세요.\n",
      "[모델]: 컴퓨터가 인간과 같은 인지 작업을 수행하도록 인간의 지능을 흉내내는 기술\n",
      "[사용자]: 의식이 있는지 40자 이내의 문장으로 답하세요.\n",
      "[모델]: 아직 의식의 정의와 존재 여부에 대한 과학적 합의 없음\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyD0jMkUWWxa6O1qpGjMIz80zOVxM4KoyKU\")\n",
    "model = genai.GenerativeModel('gemini-pro')\n",
    "user_queries = [\n",
    "    {'role': 'user', 'parts': [\"인공지능에 대해 40자 이내의 문장으로 설명하세요.\"]},\n",
    "    {'role': 'user', 'parts': [\"의식이 있는지 40자 이내의 문장으로 답하세요.\"]}\n",
    "]\n",
    "history = []\n",
    "\n",
    "for user_query in user_queries:\n",
    "    history.append(user_query)\n",
    "    print(f'[사용자]: {user_query[\"parts\"][0]}')\n",
    "    response = model.generate_content(history)    \n",
    "    # 응답의 길이가 40자를 초과하는 경우 재실행\n",
    "    while len(response.text) > 40:\n",
    "        print(f\"응답 메시지 길이: {len(response.text)}\")\n",
    "        response = model.generate_content(history)\n",
    "\n",
    "    print(f'[모델]: {response.text}')\n",
    "    history.append(response.candidates[0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9006294d-5e80-48d5-ad86-8aef1950cb5e",
   "metadata": {},
   "source": [
    "언어모델에게 40자 이내로 작성하라고 지시했지만, 항상 지시를 따르는 것은 아닙니다. 그래서 응답받은 결과의 길이를 체크해서 40자를 초과하면 재실행하도록 구현했습니다.\n",
    "\n",
    "실제 서비스를 만들다 보면 여러 가지 이유로 모델의 응답을 그대로 사용할 수 없는 경우가 발생할 수 있습니다. 그런데 ChatSession 객체를 사용하면 중간에 끼어들기가 매우 힘들기 때문에 중간에 이와 같은 로직을 구현하기가 쉽지 않습니다. 왜나하면, 앞서 다이어그램에서 봤듯이 ChatSession 객체의 send_message 메서드는 질의/응답을 대화 이력에 담는 과정을 메서드 외부로 노출하지 않기 때문입니다.\n",
    "\n",
    "하지만, 이 경우가 아니라면 ChatSession 객체를 사용하는 것이 간편할뿐더러, 뒤에서 설명하겠지만 불필요한 오버헤드도 줄일 수 있습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
