{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2ee86d06-874b-488f-b28f-0c4d343ee73e",
   "metadata": {},
   "source": [
    "## 언어모델 제어하기\n",
    "\n",
    "3장에서는 언어모델을 제어하는 두 가지 방법에 관해 다룹니다. 하나는 언어모델이 다양하게 반응할 수 있도록 만드는 여러 가지 매개변수와 그 설정 방법입니다. 다른 하나는 언어모델을 활용하여 서비스를 만들 때 유해한 서비스가 되지 않도록 메시지의 안전성을 점검하는 방법입니다. 이 가운데 매개변수를 이해하기 위해서는 언어모델의 동작 방식에 대한 지식이 선행되어야 하므로 이에 관해서도 함께 다룹니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae83d05a-28b4-4f8d-9b82-852cef8f77ca",
   "metadata": {},
   "source": [
    "### 매개변수 설정하기\n",
    "\n",
    "언어모델의 동작은 학습 시점과 실행 시점 두 단계에 의해 결정됩니다. 학습 시점에는 가중치를 업데이트하는 방식으로 모델의 물리적 실체를 완성한다면, 추론 시점(실행 시점)에는 그렇게 만들어진 모델의 출력값을 조정함으로써 언어모델이 더욱 다양하게 반응하도록 돕습니다. 학습 시점에 업데이트되는 가중치(weights)와 출력값을 조정하는 설정값 모두 매개변수라고 부르지만, 이 책에서는 특별한 경우가 아니면 두 번째 의미로 매개변수라는 용어를 사용합니다.\n",
    "<center>\n",
    "<img src='https://wikidocs.net/images/page/229810/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7_2024-02-04_093623.png' /><br>\n",
    "</center>\n",
    "\n",
    "구글 제미나이 API에서 매개변수는 GenerationConfig 객체를 통해 설정됩니다. GenerationConfig 객체에는 모델의 응답 수인 candidate_count를 포함하여 총 6개의 매개변수가 있습니다.\n",
    "\n",
    "tip => 업데이트되는 매개변수를 파라미터(parameter)라고 하고, 추론 시점에 사용되는 매개변수를 인퍼런스 파라미터(inference parameter)로 구분지어 부르기도 합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c28fbb-f4e8-4cfc-9ce9-1d610176f4eb",
   "metadata": {},
   "source": [
    "#### candidate_count\n",
    "\n",
    "1장에서 다루었던 응답 후보(Candidate) 수를 설정하는 매개변수입니다. 현재는 기본값인 1만 허용되므로 추후 구글에서 응답 후보 수를 늘리기 전까지는 별도의 설정이 불필요합니다. 만일 1이 아닌 값을 설정하면 다음과 같이 오류가 발생합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e494eebd-a3bd-4f66-a24f-3ddd34706db5",
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgument",
     "evalue": "400 Only one candidate can be specified in the current model",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgument\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m generation_config \u001b[38;5;241m=\u001b[39m genai\u001b[38;5;241m.\u001b[39mGenerationConfig(candidate_count\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m      5\u001b[0m model \u001b[38;5;241m=\u001b[39m genai\u001b[38;5;241m.\u001b[39mGenerativeModel(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgemini-1.5-flash\u001b[39m\u001b[38;5;124m'\u001b[39m, generation_config\u001b[38;5;241m=\u001b[39mgeneration_config)\n\u001b[1;32m----> 6\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m인공지능에 대해 한 문장으로 설명하세요.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(response\u001b[38;5;241m.\u001b[39mtext)\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcanidate 생성 건수: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(response\u001b[38;5;241m.\u001b[39mcandidates)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mC:\\Dev\\Python\\Python312\\Lib\\site-packages\\google\\generativeai\\generative_models.py:331\u001b[0m, in \u001b[0;36mGenerativeModel.generate_content\u001b[1;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[0;32m    329\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_iterator(iterator)\n\u001b[0;32m    330\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 331\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_content\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    332\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    333\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mrequest_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    334\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    335\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m generation_types\u001b[38;5;241m.\u001b[39mGenerateContentResponse\u001b[38;5;241m.\u001b[39mfrom_response(response)\n\u001b[0;32m    336\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m google\u001b[38;5;241m.\u001b[39mapi_core\u001b[38;5;241m.\u001b[39mexceptions\u001b[38;5;241m.\u001b[39mInvalidArgument \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mC:\\Dev\\Python\\Python312\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:830\u001b[0m, in \u001b[0;36mGenerativeServiceClient.generate_content\u001b[1;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[0;32m    827\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_universe_domain()\n\u001b[0;32m    829\u001b[0m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[1;32m--> 830\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    831\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    834\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    835\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    837\u001b[0m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[0;32m    838\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
      "File \u001b[1;32mC:\\Dev\\Python\\Python312\\Lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[0m, in \u001b[0;36m_GapicCallable.__call__\u001b[1;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[0;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    129\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m compression\n\u001b[1;32m--> 131\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Dev\\Python\\Python312\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:293\u001b[0m, in \u001b[0;36mRetry.__call__.<locals>.retry_wrapped_func\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    289\u001b[0m target \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mpartial(func, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    290\u001b[0m sleep_generator \u001b[38;5;241m=\u001b[39m exponential_sleep_generator(\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_initial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maximum, multiplier\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_multiplier\n\u001b[0;32m    292\u001b[0m )\n\u001b[1;32m--> 293\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    297\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    298\u001b[0m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    299\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Dev\\Python\\Python312\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:153\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[0;32m    150\u001b[0m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    152\u001b[0m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[1;32m--> 153\u001b[0m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    156\u001b[0m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    157\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    162\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[0;32m    164\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(sleep)\n",
      "File \u001b[1;32mC:\\Dev\\Python\\Python312\\Lib\\site-packages\\google\\api_core\\retry\\retry_base.py:212\u001b[0m, in \u001b[0;36m_retry_error_helper\u001b[1;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[0;32m    207\u001b[0m     final_exc, source_exc \u001b[38;5;241m=\u001b[39m exc_factory_fn(\n\u001b[0;32m    208\u001b[0m         error_list,\n\u001b[0;32m    209\u001b[0m         RetryFailureReason\u001b[38;5;241m.\u001b[39mNON_RETRYABLE_ERROR,\n\u001b[0;32m    210\u001b[0m         original_timeout,\n\u001b[0;32m    211\u001b[0m     )\n\u001b[1;32m--> 212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msource_exc\u001b[39;00m\n\u001b[0;32m    213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    214\u001b[0m     on_error_fn(exc)\n",
      "File \u001b[1;32mC:\\Dev\\Python\\Python312\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:144\u001b[0m, in \u001b[0;36mretry_target\u001b[1;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[0;32m    143\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 144\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    145\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39misawaitable(result):\n\u001b[0;32m    146\u001b[0m             warnings\u001b[38;5;241m.\u001b[39mwarn(_ASYNC_RETRY_WARNING)\n",
      "File \u001b[1;32mC:\\Dev\\Python\\Python312\\Lib\\site-packages\\google\\api_core\\timeout.py:120\u001b[0m, in \u001b[0;36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m     \u001b[38;5;66;03m# Avoid setting negative timeout\u001b[39;00m\n\u001b[0;32m    118\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout \u001b[38;5;241m-\u001b[39m time_since_first_attempt)\n\u001b[1;32m--> 120\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Dev\\Python\\Python312\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:78\u001b[0m, in \u001b[0;36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m grpc\u001b[38;5;241m.\u001b[39mRpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m---> 78\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions\u001b[38;5;241m.\u001b[39mfrom_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mInvalidArgument\u001b[0m: 400 Only one candidate can be specified in the current model"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyD0jMkUWWxa6O1qpGjMIz80zOVxM4KoyKU\")\n",
    "generation_config = genai.GenerationConfig(candidate_count=2)\n",
    "model = genai.GenerativeModel('gemini-1.5-flash', generation_config=generation_config)\n",
    "response = model.generate_content(\"인공지능에 대해 한 문장으로 설명하세요.\")\n",
    "print(response.text)\n",
    "print(f\"canidate 생성 건수: {len(response.candidates)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534aaa02-0f71-4cee-bc79-01c8a1800a1e",
   "metadata": {},
   "source": [
    "#### stop_sequences\n",
    "\n",
    "언어모델이 언어를 생성하다가 stop_sequences에 있는 문자열을 만나면 생성을 중단합니다. 민감한 어휘의 등장을 막거나, 응답 길이를 제한할 때 유용하게 사용할 수 있습니다. 다음은 마침표나 느낌표가 등장하면 언어 생성을 중지시키는 코드입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e49d7a40-6277-4506-b6b9-9007f11df26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## 인공지능(AI)에 대해 설명해 드릴게요!\n",
      "\n",
      "**인공지능(AI)**은 컴퓨터가 인간처럼 생각하고 행동할 수 있도록 하는 기술입니다\n"
     ]
    }
   ],
   "source": [
    "import google.generativeai as genai\n",
    "\n",
    "genai.configure(api_key=\"AIzaSyD0jMkUWWxa6O1qpGjMIz80zOVxM4KoyKU\")\n",
    "generation_config = genai.GenerationConfig(stop_sequences=[\". \",\"! \"])\n",
    "model = genai.GenerativeModel('gemini-1.5-flash', generation_config=generation_config)\n",
    "response = model.generate_content(\"인공지능에 대해 설명하세요.\")\n",
    "\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7202d7-52ee-4275-99cf-6ffeaaeb66e1",
   "metadata": {},
   "source": [
    "출력 결과에서 알 수 있듯이 온점(.)이 나타나자 언어 생성을 멈추었으며, 결과 반환 시 온점까지도 제외되었습니다. 참고로, stop_sequences는 최대 5개까지 설정할 수 있으며, 초과 시 InvalidArgument 오류가 발생합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac7b43c-76ca-44ee-b37e-312033b8734e",
   "metadata": {},
   "source": [
    "#### max_output_tokens\n",
    "\n",
    "언어모델에게 언어의 최소 단위는 토큰입니다. 다음은 OpenAI GPT 모델의 토큰 예시입니다.\n",
    "\n",
    "<center>\n",
    "<img src='https://wikidocs.net/images/page/229813/%EC%8A%A4%ED%81%AC%EB%A6%B0%EC%83%B7_2024-02-04_083412_.png' /><br>\n",
    "</center>\n",
    "출처: platform.openai.com/tokenizer\n",
    "\n",
    "\"Learn about language model tokenization.\"이라는 문장이 총 7개의 토큰으로 표현되었습니다. 색깔에서 보듯이 한 개의 토큰이 단어 하나에 대응되는 것은 아닙니다. 토큰 하나가 단어의 일부만 표현할 수도 있고, 여러 개의 단어를 표현할 수도 있습니다. 구글 제미나이 SDK를 사용하면 다음의 메서드를 통해 토큰 수를 확인할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8ead1c92-a2a7-4ea2-934c-d1d7daffcf7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_tokens: 7\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokens = model.count_tokens(\"Learn about language model tokenization.\")\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e3383c-2602-4076-9940-467fc1349343",
   "metadata": {},
   "source": [
    "제미나이 프로 모델은 영어의 경우 토큰 1개로 약 4글자를 표현합니다. 이에 비해 한글은 토큰 1개로 대략 1.5자를 표현합니다.\n",
    "\n",
    "구글 제미나이 SDK에서 max_output_tokens는 모델이 생성하는 메시지가 최대 토큰 수를 넘지 않도록 제어하는 매개변수입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb13e550-9bd8-463d-8b28-ac6ec3af84c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "candidates {\n",
      "  content {\n",
      "    parts {\n",
      "      text: \"인공지능은 컴퓨터 시\"\n",
      "    }\n",
      "    role: \"model\"\n",
      "  }\n",
      "  finish_reason: MAX_TOKENS\n",
      "  index: 0\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_SEXUALLY_EXPLICIT\n",
      "    probability: NEGLIGIBLE\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HATE_SPEECH\n",
      "    probability: NEGLIGIBLE\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_HARASSMENT\n",
      "    probability: NEGLIGIBLE\n",
      "  }\n",
      "  safety_ratings {\n",
      "    category: HARM_CATEGORY_DANGEROUS_CONTENT\n",
      "    probability: NEGLIGIBLE\n",
      "  }\n",
      "}\n",
      "usage_metadata {\n",
      "  prompt_token_count: 14\n",
      "  candidates_token_count: 10\n",
      "  total_token_count: 24\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "generation_config = genai.GenerationConfig(max_output_tokens=10)\n",
    "model = genai.GenerativeModel('gemini-1.5-flash', generation_config=generation_config)\n",
    "user_message = \"인공지능에 대해 한 문장으로 설명하세요.\"\n",
    "response = model.generate_content(user_message)\n",
    "print(response._result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13029ce-e7df-4b25-b089-38464356e5c8",
   "metadata": {},
   "source": [
    "max_output_tokens=10으로 세팅했을 때 finish_reason이 MAX_TOKENS로 출력된 것을 볼 수 있습니다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
